{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Kaggle 2021-10 Playground.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOJ0iYzLD3t5",
    "outputId": "5876a224-3457-4129-e282-939afd75b4dd"
   },
   "source": [
    "# !pip install -U -q kaggle\n",
    "# !mkdir -p ~/.kaggle\n",
    "# !echo '{\"username\":\"harrierdb\",\"key\":\"d35f4ee749dde0ec819807713df28790\"}' > ~/.kaggle/kaggle.json\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    " \n",
    "# !kaggle competitions download -c tabular-playground-series-oct-2021 --force"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
      "Downloading test.csv.zip to /content\n",
      " 97% 425M/438M [00:02<00:00, 148MB/s]\n",
      "100% 438M/438M [00:03<00:00, 153MB/s]\n",
      "Downloading sample_submission.csv.zip to /content\n",
      "  0% 0.00/1.12M [00:00<?, ?B/s]\n",
      "100% 1.12M/1.12M [00:00<00:00, 71.0MB/s]\n",
      "Downloading train.csv.zip to /content\n",
      " 99% 868M/877M [00:06<00:00, 143MB/s]\n",
      "100% 877M/877M [00:06<00:00, 147MB/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0aD_vUMtlfXa",
    "outputId": "1b362a55-5c46-4cac-f54a-1fe2e08f2776"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install catboost\n",
    "import gc"
   ],
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "flhdicrclfpf"
   },
   "source": [
    "data = pd.read_csv('./train.csv.zip', index_col = 0, nrows = 5000)\n",
    "data_test = pd.read_csv('./test.csv.zip', index_col = 0, nrows = 1000)\n"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "GQoM5HCLlfro",
    "outputId": "e378aaa9-d859-4783-eb85-17b269f75d47"
   },
   "source": [
    "\n",
    "data_test['target'] = -1\n",
    "data.head()"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "      <th>f31</th>\n",
       "      <th>f32</th>\n",
       "      <th>f33</th>\n",
       "      <th>f34</th>\n",
       "      <th>f35</th>\n",
       "      <th>f36</th>\n",
       "      <th>f37</th>\n",
       "      <th>f38</th>\n",
       "      <th>f39</th>\n",
       "      <th>...</th>\n",
       "      <th>f246</th>\n",
       "      <th>f247</th>\n",
       "      <th>f248</th>\n",
       "      <th>f249</th>\n",
       "      <th>f250</th>\n",
       "      <th>f251</th>\n",
       "      <th>f252</th>\n",
       "      <th>f253</th>\n",
       "      <th>f254</th>\n",
       "      <th>f255</th>\n",
       "      <th>f256</th>\n",
       "      <th>f257</th>\n",
       "      <th>f258</th>\n",
       "      <th>f259</th>\n",
       "      <th>f260</th>\n",
       "      <th>f261</th>\n",
       "      <th>f262</th>\n",
       "      <th>f263</th>\n",
       "      <th>f264</th>\n",
       "      <th>f265</th>\n",
       "      <th>f266</th>\n",
       "      <th>f267</th>\n",
       "      <th>f268</th>\n",
       "      <th>f269</th>\n",
       "      <th>f270</th>\n",
       "      <th>f271</th>\n",
       "      <th>f272</th>\n",
       "      <th>f273</th>\n",
       "      <th>f274</th>\n",
       "      <th>f275</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.205979</td>\n",
       "      <td>0.410993</td>\n",
       "      <td>0.176775</td>\n",
       "      <td>0.223581</td>\n",
       "      <td>0.423543</td>\n",
       "      <td>0.476140</td>\n",
       "      <td>0.413590</td>\n",
       "      <td>0.612021</td>\n",
       "      <td>0.534873</td>\n",
       "      <td>0.147295</td>\n",
       "      <td>0.026177</td>\n",
       "      <td>0.106613</td>\n",
       "      <td>0.200924</td>\n",
       "      <td>0.713191</td>\n",
       "      <td>0.155750</td>\n",
       "      <td>0.557335</td>\n",
       "      <td>0.341702</td>\n",
       "      <td>0.285720</td>\n",
       "      <td>0.230396</td>\n",
       "      <td>0.203957</td>\n",
       "      <td>0.509588</td>\n",
       "      <td>0.706972</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007793</td>\n",
       "      <td>0.247765</td>\n",
       "      <td>0.263750</td>\n",
       "      <td>0.259555</td>\n",
       "      <td>0.231730</td>\n",
       "      <td>0.138379</td>\n",
       "      <td>0.197824</td>\n",
       "      <td>0.054392</td>\n",
       "      <td>0.194153</td>\n",
       "      <td>0.281500</td>\n",
       "      <td>0.034818</td>\n",
       "      <td>0.025334</td>\n",
       "      <td>0.114432</td>\n",
       "      <td>0.139203</td>\n",
       "      <td>0.246157</td>\n",
       "      <td>0.251371</td>\n",
       "      <td>0.701423</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181004</td>\n",
       "      <td>0.473119</td>\n",
       "      <td>0.011734</td>\n",
       "      <td>0.213657</td>\n",
       "      <td>0.619678</td>\n",
       "      <td>0.441593</td>\n",
       "      <td>0.230407</td>\n",
       "      <td>0.686013</td>\n",
       "      <td>0.281971</td>\n",
       "      <td>0.238509</td>\n",
       "      <td>0.493411</td>\n",
       "      <td>0.107277</td>\n",
       "      <td>0.231828</td>\n",
       "      <td>0.457150</td>\n",
       "      <td>0.395200</td>\n",
       "      <td>0.617088</td>\n",
       "      <td>0.459358</td>\n",
       "      <td>0.209225</td>\n",
       "      <td>0.201098</td>\n",
       "      <td>0.199383</td>\n",
       "      <td>0.366578</td>\n",
       "      <td>0.585788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285311</td>\n",
       "      <td>0.400367</td>\n",
       "      <td>0.162493</td>\n",
       "      <td>0.249365</td>\n",
       "      <td>0.141160</td>\n",
       "      <td>0.133688</td>\n",
       "      <td>0.247906</td>\n",
       "      <td>0.139251</td>\n",
       "      <td>0.216444</td>\n",
       "      <td>0.109674</td>\n",
       "      <td>0.033018</td>\n",
       "      <td>0.017458</td>\n",
       "      <td>0.189336</td>\n",
       "      <td>0.168785</td>\n",
       "      <td>0.184251</td>\n",
       "      <td>0.202753</td>\n",
       "      <td>0.218451</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.182583</td>\n",
       "      <td>0.307431</td>\n",
       "      <td>0.325950</td>\n",
       "      <td>0.207116</td>\n",
       "      <td>0.605699</td>\n",
       "      <td>0.309695</td>\n",
       "      <td>0.493337</td>\n",
       "      <td>0.751107</td>\n",
       "      <td>0.536272</td>\n",
       "      <td>0.286813</td>\n",
       "      <td>0.139532</td>\n",
       "      <td>0.107222</td>\n",
       "      <td>0.247791</td>\n",
       "      <td>0.631949</td>\n",
       "      <td>0.347463</td>\n",
       "      <td>0.642173</td>\n",
       "      <td>0.257763</td>\n",
       "      <td>0.162548</td>\n",
       "      <td>0.327377</td>\n",
       "      <td>0.193583</td>\n",
       "      <td>0.495440</td>\n",
       "      <td>0.636742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.309747</td>\n",
       "      <td>0.221081</td>\n",
       "      <td>0.284810</td>\n",
       "      <td>0.230828</td>\n",
       "      <td>0.138271</td>\n",
       "      <td>0.199742</td>\n",
       "      <td>0.060408</td>\n",
       "      <td>0.146746</td>\n",
       "      <td>0.208131</td>\n",
       "      <td>0.035977</td>\n",
       "      <td>0.022631</td>\n",
       "      <td>0.113542</td>\n",
       "      <td>0.274871</td>\n",
       "      <td>0.182770</td>\n",
       "      <td>0.151502</td>\n",
       "      <td>0.570035</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.180240</td>\n",
       "      <td>0.494592</td>\n",
       "      <td>0.008367</td>\n",
       "      <td>0.223580</td>\n",
       "      <td>0.760618</td>\n",
       "      <td>0.439211</td>\n",
       "      <td>0.432055</td>\n",
       "      <td>0.776147</td>\n",
       "      <td>0.483958</td>\n",
       "      <td>0.260886</td>\n",
       "      <td>0.147122</td>\n",
       "      <td>0.105433</td>\n",
       "      <td>0.287755</td>\n",
       "      <td>0.455777</td>\n",
       "      <td>0.247971</td>\n",
       "      <td>0.616628</td>\n",
       "      <td>0.335907</td>\n",
       "      <td>0.337025</td>\n",
       "      <td>0.239127</td>\n",
       "      <td>0.176163</td>\n",
       "      <td>0.538269</td>\n",
       "      <td>0.706468</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008829</td>\n",
       "      <td>0.353799</td>\n",
       "      <td>0.219977</td>\n",
       "      <td>0.266858</td>\n",
       "      <td>0.145617</td>\n",
       "      <td>0.138590</td>\n",
       "      <td>0.234925</td>\n",
       "      <td>0.059817</td>\n",
       "      <td>0.140886</td>\n",
       "      <td>0.205023</td>\n",
       "      <td>0.319312</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>0.112291</td>\n",
       "      <td>0.288915</td>\n",
       "      <td>0.332632</td>\n",
       "      <td>0.140831</td>\n",
       "      <td>0.473845</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177172</td>\n",
       "      <td>0.495513</td>\n",
       "      <td>0.014263</td>\n",
       "      <td>0.548819</td>\n",
       "      <td>0.625396</td>\n",
       "      <td>0.562493</td>\n",
       "      <td>0.117158</td>\n",
       "      <td>0.561255</td>\n",
       "      <td>0.077115</td>\n",
       "      <td>0.158321</td>\n",
       "      <td>0.260239</td>\n",
       "      <td>0.102561</td>\n",
       "      <td>0.265285</td>\n",
       "      <td>0.503776</td>\n",
       "      <td>0.269776</td>\n",
       "      <td>0.545945</td>\n",
       "      <td>0.319548</td>\n",
       "      <td>0.278538</td>\n",
       "      <td>0.214922</td>\n",
       "      <td>0.200239</td>\n",
       "      <td>0.534551</td>\n",
       "      <td>0.728652</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004840</td>\n",
       "      <td>0.323546</td>\n",
       "      <td>0.166292</td>\n",
       "      <td>0.285516</td>\n",
       "      <td>0.208651</td>\n",
       "      <td>0.200394</td>\n",
       "      <td>0.198155</td>\n",
       "      <td>0.414729</td>\n",
       "      <td>0.251997</td>\n",
       "      <td>0.193405</td>\n",
       "      <td>0.034490</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>0.197312</td>\n",
       "      <td>0.207429</td>\n",
       "      <td>0.255857</td>\n",
       "      <td>0.139875</td>\n",
       "      <td>0.321039</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f0        f1        f2        f3  ...  f282  f283  f284  target\n",
       "id                                          ...                          \n",
       "0   0.205979  0.410993  0.176775  0.223581  ...     0     0     0       1\n",
       "1   0.181004  0.473119  0.011734  0.213657  ...     0     0     0       1\n",
       "2   0.182583  0.307431  0.325950  0.207116  ...     0     0     0       1\n",
       "3   0.180240  0.494592  0.008367  0.223580  ...     0     0     0       1\n",
       "4   0.177172  0.495513  0.014263  0.548819  ...     0     1     0       1\n",
       "\n",
       "[5 rows x 286 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i470xcYilftn",
    "outputId": "6485050b-567d-4182-d6d5-cd86a0b0a313"
   },
   "source": [
    "df = data.append(data_test)\n",
    "df.info()"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6000 entries, 0 to 1000999\n",
      "Columns: 286 entries, f0 to target\n",
      "dtypes: float64(240), int64(46)\n",
      "memory usage: 13.1 MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PntOFdjB2UOP"
   },
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yf7uSFsX3N8R"
   },
   "source": [
    "lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'n_estimators': 20000,\n",
    "        'random_state': 42,\n",
    "        'learning_rate': 8e-3,\n",
    "        'subsample': 0.6,\n",
    "        'subsample_freq': 1,\n",
    "        'colsample_bytree': 0.4,\n",
    "        'reg_alpha': 10.0,\n",
    "        'reg_lambda': 1e-1,\n",
    "        'min_child_weight': 256,\n",
    "        'min_child_samples': 500,\n",
    "}\n",
    "xgb_params = {'n_estimators': 10000,\n",
    "        'learning_rate': 0.03689407512484644,\n",
    "        'max_depth': 8,\n",
    "        'colsample_bytree': 0.3723914688159835,\n",
    "        'subsample': 0.780714581166012,\n",
    "        'eval_metric': 'auc',\n",
    "        'use_label_encoder': False,\n",
    "        'gamma': 0,\n",
    "        'reg_lambda': 50.0,\n",
    "        'random_state': 42}\n",
    "\n",
    "cat_params = {'iterations': 17298,\n",
    "        'learning_rate': 0.03429054860458741,\n",
    "        'reg_lambda': 0.3242286463210283,\n",
    "        'subsample': 0.9433911589913944,\n",
    "        'random_strength': 22.4849972385133,\n",
    "        'depth': 8,\n",
    "        'min_data_in_leaf': 4,\n",
    "        'leaf_estimation_iterations': 8,\n",
    "        'task_type':\"GPU\",\n",
    "        'bootstrap_type':'Poisson',\n",
    "        'verbose' : 500,\n",
    "        'early_stopping_rounds' : 200,\n",
    "        'eval_metric' : 'AUC'}\n",
    "lgb = LGBMClassifier(**lgb_params)\n",
    "xgb = XGBClassifier(**xgb_params)\n",
    "cat = CatBoostClassifier(**cat_params)"
   ],
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9HlySJ-pptdq"
   },
   "source": [
    "\n",
    "\n",
    "def get_oof(feats, target, test, kfold, clf):\n",
    "  oof_preds = np.zeros(feats.shape[0])\n",
    "  sub_preds = np.zeros(test.shape[0])\n",
    "  for i, (train_idx, valid_idx) in enumerate(kfold.split(feats)):\n",
    "    train_X, train_y = feats.loc[train_idx], target.loc[train_idx]\n",
    "    valid_X, valid_y = feats.loc[valid_idx], target.loc[valid_idx]\n",
    "\n",
    "    clf.fit(train_X, train_y, eval_set = [(valid_X, valid_y)], verbose = 500, early_stopping_rounds = 500, )\n",
    "    oof_preds[valid_idx] = clf.predict_proba(valid_X)[:,1]\n",
    "    sub_preds += clf.predict_proba(test)[:,1]\n",
    "    del train_X, train_y, valid_X, valid_y\n",
    "    gc.collect()\n",
    "\n",
    "  evalution_result = roc_auc_score(target, oof_preds)\n",
    "  print('*'*10)\n",
    "  print('roc auc score:', evalution_result)\n",
    "  print('*'*20)\n",
    "  sub_preds_result = sub_preds / kfold.n_splits\n",
    "  return oof_preds ,sub_preds_result\n"
   ],
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "R2adCLQOwlvU"
   },
   "source": [
    "feats = df.loc[df['target']!=-1, :].drop('target', axis = 1)\n",
    "target = df.loc[df['target']!=-1,'target']\n",
    "test = df.loc[df['target']==-1,:].drop('target', axis = 1)\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 2021)\n"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oeOElyMrvLyO",
    "outputId": "4df4e4f5-63cb-4330-e7ca-1cff02d0b3c5"
   },
   "source": [
    "# xgboost, lightgbm, catboost\n",
    "\n",
    "oof_preds_1, sub_preds_1 = get_oof(feats, target, test, kfold, lgb)\n",
    "oof_preds_2, sub_preds_2 = get_oof(feats, target, test, kfold, xgb)\n"
   ],
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.572715\tvalid_1's binary_logloss: 0.564124\n",
      "[1000]\ttraining's binary_logloss: 0.563261\tvalid_1's binary_logloss: 0.558674\n",
      "[1500]\ttraining's binary_logloss: 0.558226\tvalid_1's binary_logloss: 0.556823\n",
      "[2000]\ttraining's binary_logloss: 0.554538\tvalid_1's binary_logloss: 0.556036\n",
      "[2500]\ttraining's binary_logloss: 0.551533\tvalid_1's binary_logloss: 0.555614\n",
      "[3000]\ttraining's binary_logloss: 0.548976\tvalid_1's binary_logloss: 0.555475\n",
      "[3500]\ttraining's binary_logloss: 0.546752\tvalid_1's binary_logloss: 0.555404\n",
      "[4000]\ttraining's binary_logloss: 0.544795\tvalid_1's binary_logloss: 0.555387\n",
      "Early stopping, best iteration is:\n",
      "[3760]\ttraining's binary_logloss: 0.545699\tvalid_1's binary_logloss: 0.555256\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.574733\tvalid_1's binary_logloss: 0.561744\n",
      "[1000]\ttraining's binary_logloss: 0.566851\tvalid_1's binary_logloss: 0.556778\n",
      "[1500]\ttraining's binary_logloss: 0.561573\tvalid_1's binary_logloss: 0.553933\n",
      "[2000]\ttraining's binary_logloss: 0.557891\tvalid_1's binary_logloss: 0.552798\n",
      "[2500]\ttraining's binary_logloss: 0.554807\tvalid_1's binary_logloss: 0.551829\n",
      "[3000]\ttraining's binary_logloss: 0.552234\tvalid_1's binary_logloss: 0.551339\n",
      "[3500]\ttraining's binary_logloss: 0.549977\tvalid_1's binary_logloss: 0.550938\n",
      "[4000]\ttraining's binary_logloss: 0.548021\tvalid_1's binary_logloss: 0.550773\n",
      "[4500]\ttraining's binary_logloss: 0.546286\tvalid_1's binary_logloss: 0.550929\n",
      "Early stopping, best iteration is:\n",
      "[4177]\ttraining's binary_logloss: 0.547399\tvalid_1's binary_logloss: 0.5507\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.570453\tvalid_1's binary_logloss: 0.570842\n",
      "[1000]\ttraining's binary_logloss: 0.563048\tvalid_1's binary_logloss: 0.565255\n",
      "[1500]\ttraining's binary_logloss: 0.557791\tvalid_1's binary_logloss: 0.562834\n",
      "[2000]\ttraining's binary_logloss: 0.553983\tvalid_1's binary_logloss: 0.561203\n",
      "[2500]\ttraining's binary_logloss: 0.550974\tvalid_1's binary_logloss: 0.560419\n",
      "[3000]\ttraining's binary_logloss: 0.548354\tvalid_1's binary_logloss: 0.56002\n",
      "[3500]\ttraining's binary_logloss: 0.546061\tvalid_1's binary_logloss: 0.559662\n",
      "Early stopping, best iteration is:\n",
      "[3391]\ttraining's binary_logloss: 0.546561\tvalid_1's binary_logloss: 0.559604\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.562589\tvalid_1's binary_logloss: 0.576078\n",
      "[1000]\ttraining's binary_logloss: 0.554747\tvalid_1's binary_logloss: 0.571057\n",
      "[1500]\ttraining's binary_logloss: 0.550057\tvalid_1's binary_logloss: 0.568981\n",
      "[2000]\ttraining's binary_logloss: 0.546498\tvalid_1's binary_logloss: 0.567597\n",
      "[2500]\ttraining's binary_logloss: 0.543543\tvalid_1's binary_logloss: 0.567014\n",
      "[3000]\ttraining's binary_logloss: 0.541135\tvalid_1's binary_logloss: 0.56667\n",
      "[3500]\ttraining's binary_logloss: 0.539082\tvalid_1's binary_logloss: 0.566304\n",
      "[4000]\ttraining's binary_logloss: 0.53725\tvalid_1's binary_logloss: 0.566201\n",
      "Early stopping, best iteration is:\n",
      "[3713]\ttraining's binary_logloss: 0.538268\tvalid_1's binary_logloss: 0.56607\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.568828\tvalid_1's binary_logloss: 0.590323\n",
      "[1000]\ttraining's binary_logloss: 0.561304\tvalid_1's binary_logloss: 0.584826\n",
      "[1500]\ttraining's binary_logloss: 0.556682\tvalid_1's binary_logloss: 0.582446\n",
      "[2000]\ttraining's binary_logloss: 0.552946\tvalid_1's binary_logloss: 0.581131\n",
      "[2500]\ttraining's binary_logloss: 0.549788\tvalid_1's binary_logloss: 0.580558\n",
      "[3000]\ttraining's binary_logloss: 0.546618\tvalid_1's binary_logloss: 0.579659\n",
      "[3500]\ttraining's binary_logloss: 0.544312\tvalid_1's binary_logloss: 0.579487\n",
      "Early stopping, best iteration is:\n",
      "[3398]\ttraining's binary_logloss: 0.544745\tvalid_1's binary_logloss: 0.579359\n",
      "**********\n",
      "roc auc score: 0.8123990027683805\n",
      "********************\n",
      "[0]\tvalidation_0-auc:0.703873\tvalidation_1-auc:0.540505\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 500 rounds.\n",
      "[500]\tvalidation_0-auc:0.999987\tvalidation_1-auc:0.848082\n",
      "Stopping. Best iteration:\n",
      "[458]\tvalidation_0-auc:0.999935\tvalidation_1-auc:0.848886\n",
      "\n",
      "[0]\tvalidation_0-auc:0.664121\tvalidation_1-auc:0.531597\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 500 rounds.\n",
      "[500]\tvalidation_0-auc:0.999994\tvalidation_1-auc:0.854154\n",
      "[1000]\tvalidation_0-auc:1\tvalidation_1-auc:0.853981\n",
      "Stopping. Best iteration:\n",
      "[917]\tvalidation_0-auc:1\tvalidation_1-auc:0.854802\n",
      "\n",
      "[0]\tvalidation_0-auc:0.671231\tvalidation_1-auc:0.528541\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 500 rounds.\n",
      "[500]\tvalidation_0-auc:0.999991\tvalidation_1-auc:0.837302\n",
      "Stopping. Best iteration:\n",
      "[456]\tvalidation_0-auc:0.999955\tvalidation_1-auc:0.837874\n",
      "\n",
      "[0]\tvalidation_0-auc:0.717713\tvalidation_1-auc:0.519712\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 500 rounds.\n",
      "[500]\tvalidation_0-auc:0.999988\tvalidation_1-auc:0.824818\n",
      "[1000]\tvalidation_0-auc:1\tvalidation_1-auc:0.82454\n",
      "Stopping. Best iteration:\n",
      "[676]\tvalidation_0-auc:1\tvalidation_1-auc:0.825374\n",
      "\n",
      "[0]\tvalidation_0-auc:0.692527\tvalidation_1-auc:0.51464\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 500 rounds.\n",
      "[500]\tvalidation_0-auc:0.999995\tvalidation_1-auc:0.818018\n",
      "Stopping. Best iteration:\n",
      "[491]\tvalidation_0-auc:0.999991\tvalidation_1-auc:0.818338\n",
      "\n",
      "**********\n",
      "roc auc score: 0.8351012917401871\n",
      "********************\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ueZqmmHSBn1J",
    "outputId": "16307090-d8d3-4a2b-a098-540e07dd5057"
   },
   "source": [
    "oof_preds_3, sub_preds_3 = get_oof(feats, target, test, kfold, cat)  #调整eval_set = [(valid_X, valid_y)]"
   ],
   "execution_count": 40,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:\tlearn: 0.8041800\ttest: 0.8122180\tbest: 0.8122180 (0)\ttotal: 94.2ms\tremaining: 27m 8s\n",
      "500:\tlearn: 0.9999830\ttest: 0.8433140\tbest: 0.8476583 (353)\ttotal: 57.4s\tremaining: 32m 5s\n",
      "bestTest = 0.8476582766\n",
      "bestIteration = 353\n",
      "Shrink model to first 354 iterations.\n",
      "0:\tlearn: 0.7652475\ttest: 0.7740689\tbest: 0.7740689 (0)\ttotal: 124ms\tremaining: 35m 37s\n",
      "500:\tlearn: 0.9998797\ttest: 0.8480409\tbest: 0.8508911 (123)\ttotal: 58.1s\tremaining: 32m 28s\n",
      "bestTest = 0.8508911133\n",
      "bestIteration = 123\n",
      "Shrink model to first 124 iterations.\n",
      "0:\tlearn: 0.7667292\ttest: 0.7708457\tbest: 0.7708457 (0)\ttotal: 64.7ms\tremaining: 18m 38s\n",
      "500:\tlearn: 0.9999868\ttest: 0.8283938\tbest: 0.8318899 (395)\ttotal: 58.2s\tremaining: 32m 32s\n",
      "bestTest = 0.8318899274\n",
      "bestIteration = 395\n",
      "Shrink model to first 396 iterations.\n",
      "0:\tlearn: 0.7717876\ttest: 0.7323637\tbest: 0.7323637 (0)\ttotal: 66.4ms\tremaining: 19m 9s\n",
      "500:\tlearn: 0.9999688\ttest: 0.8186004\tbest: 0.8200089 (373)\ttotal: 58.1s\tremaining: 32m 28s\n",
      "1000:\tlearn: 1.0000000\ttest: 0.8239087\tbest: 0.8239087 (1000)\ttotal: 1m 59s\tremaining: 32m 28s\n",
      "1500:\tlearn: 1.0000000\ttest: 0.8228301\tbest: 0.8253213 (1255)\ttotal: 2m 58s\tremaining: 31m 18s\n",
      "bestTest = 0.8253212571\n",
      "bestIteration = 1255\n",
      "Shrink model to first 1256 iterations.\n",
      "0:\tlearn: 0.7808678\ttest: 0.7255065\tbest: 0.7255065 (0)\ttotal: 119ms\tremaining: 34m 23s\n",
      "500:\tlearn: 0.9999262\ttest: 0.8100327\tbest: 0.8109928 (416)\ttotal: 57.8s\tremaining: 32m 16s\n",
      "bestTest = 0.8109927773\n",
      "bestIteration = 416\n",
      "Shrink model to first 417 iterations.\n",
      "**********\n",
      "roc auc score: 0.8282819778683214\n",
      "********************\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cKDERzwFRntG"
   },
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "def stack_model(train_stack, test_stack, y):  #oof_set =[oof_1, oof_2, oof_3, ..., oof_n], predictions_set =[predictions_1, predictions_2, predictions_3, ..., predictions_n],\n",
    "\n",
    "    oof = np.zeros((train_stack.shape[0],))\n",
    "    predictions = np.zeros((test_stack.shape[0],))\n",
    "    scores = []\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(kfold.split(train_stack, y)):\n",
    "        trn_data, trn_y = train_stack[trn_idx], y[trn_idx]\n",
    "        val_data, val_y = train_stack[val_idx], y[val_idx]\n",
    "\n",
    "        clf = RidgeClassifier(random_state=2099)\n",
    "        clf.fit(trn_data, trn_y)\n",
    "\n",
    "        oof[val_idx] = clf._predict_proba_lr(val_data)[:,1]\n",
    "        predictions +=clf._predict_proba_lr(test_stack)[:,1] / kfold.n_splits\n",
    "\n",
    "        score_single = roc_auc_score(val_y, oof[val_idx])\n",
    "        scores.append(score_single)\n",
    "    print('mean: ', np.mean(scores))\n",
    "\n",
    "    return oof, predictions\n",
    "\n"
   ],
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P34Nv14ARnz5",
    "outputId": "4df28308-aa94-4dff-a840-7ed73bfd44c1"
   },
   "source": [
    "pred_matrix = np.hstack([sub_preds_1[:,np.newaxis], sub_preds_2[:,np.newaxis], sub_preds_3[:,np.newaxis]])\n",
    "oof_matrix = np.hstack([oof_preds_1[:,np.newaxis], oof_preds_2[:,np.newaxis], oof_preds_3[:,np.newaxis]])\n",
    "\n",
    "oof_stack, predictions_stack = stack_model(oof_matrix, pred_matrix, target)"
   ],
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean:  0.8398889571015561\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KwgMfYAGQrMb"
   },
   "source": [
    "result = pd.DataFrame({'id':test.index, 'target': predictions_stack})\n",
    "# predictions_stack.to_csv('./stack_model.csv', index)"
   ],
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "49VP09hbQrPR",
    "outputId": "1904b229-04d9-4f43-8f6a-618b7815e49d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "result"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.612764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>0.359968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000002</td>\n",
       "      <td>0.671185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000003</td>\n",
       "      <td>0.660531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000004</td>\n",
       "      <td>0.349935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1000995</td>\n",
       "      <td>0.494666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1000996</td>\n",
       "      <td>0.693508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1000997</td>\n",
       "      <td>0.451942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1000998</td>\n",
       "      <td>0.667875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000999</td>\n",
       "      <td>0.581633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0    1000000  0.612764\n",
       "1    1000001  0.359968\n",
       "2    1000002  0.671185\n",
       "3    1000003  0.660531\n",
       "4    1000004  0.349935\n",
       "..       ...       ...\n",
       "995  1000995  0.494666\n",
       "996  1000996  0.693508\n",
       "997  1000997  0.451942\n",
       "998  1000998  0.667875\n",
       "999  1000999  0.581633\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ]
  }
 ]
}